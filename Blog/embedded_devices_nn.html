<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Cheng Kang (康成)</title><meta name="author" content="Cheng"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 7.3.0"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Cheng Kang (康成)</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/#About"> Profile</a></li><li class="menus_item"><a class="site-page" href="/Publications/#index"> Publications</a></li><li class="menus_item"><a class="site-page" href="/Projects/#index"> Projects</a></li><li class="menus_item"><a class="site-page" href="/Volunteer/#index"> Volunteer Experience</a></li><li class="menus_item"><a class="site-page" href="/Blog/#index"> Blog</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/Kang.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Cheng</h3><p class="author-bio">Cognitive Researcher.</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://twitter.com/kangcheng520" target="_blank"><i class="fab fa-twitter" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.facebook.com/kang.cheng.108" target="_blank"><i class="fab fa-facebook-square" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://github.com/ChengKang520" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.linkedin.com/in/kang-cheng-9a7781180/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/img/weixin.png" target="_blank"><i class="fab fa-weixin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto:kangchen@fel.cvut.cz" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="https://scholar.google.cz/citations?user=2gOnGH4AAAAJ&amp;hl=cs&amp;oi=sra" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="https://orcid.org/0000-0001-9546-4585" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li><li><a class="e-social-link" href="/attaches/Kang_CV.pdf" target="_blank"><i class="fas fa-cloud-download-alt" aria-hidden="true"></i><span>CV</span></a></li></ul></div><a class="cv-links" href="/attaches/F3-D-2025-Kang-Cheng-Kang-Cheng-Thesis-2025.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>Doctoral Thesis</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">Embedding Neural Networks into Devices</h2><article><p>The aim of this project is to design a neural network model to recognize human activities and then use Tensorflow Lite which is a kind of deep learning framework focused on embedded devices to deploy the designed model into the microcontroller. The following objectives should be done:</p>
<ol>
<li><a href="#a"><font face="Black" size="3"> Follow the tutorial to get the simple audio recognition with the CNN Model and learn Tensorflow Lite about how to load deep learning into the device;</font></a></li>
<li><a href="#b"><font face="Black" size="3"> Design the deep learning models for human activities recognition (HAR) and make sure it can be worked in the microcontroller;</font></a></li>
<li><a href="#c"><font face="Black" size="3"> Using Make to build binary file and deploy it to the microcontroller;</font></a></li>
<li><a href="#d"><font face="Black" size="3"> Measure model and microcontroller in terms of accuracy, power consumption and memory footprint;</font></a></li>
<li><a href="#e"><font face="Black" size="3"> Conclusion.</font></a></li>
</ol>
<p><span style="font-family:Papyrus; font-size:2em;"> You can find the codes from this: </span><iframe
style="margin-left: 2px; margin-bottom:-5px;"
frameborder="0" scrolling="0" width="100px" height="20px"
src="https://ghbtns.com/github-btn.html?user=chengkang520&repo=har_embedded_system&type=star&count=true" ></p>
</iframe>


<hr>
<h2 id="Follow-the-tutorial-to-get-the-simple-audio-recognition-with-the-CNN-Model-and-learn-Tensorflow-Lite-about-how-to-load-deep-learning-into-the-device"><a href="#Follow-the-tutorial-to-get-the-simple-audio-recognition-with-the-CNN-Model-and-learn-Tensorflow-Lite-about-how-to-load-deep-learning-into-the-device" class="headerlink" title="Follow the tutorial to get the simple audio recognition with the CNN Model and learn Tensorflow Lite about how to load deep learning into the device "></a>Follow the tutorial to get the simple audio recognition with the CNN Model and learn Tensorflow Lite about how to load deep learning into the device <a name="a"></a></h2><p>We choose the <a target="_blank" rel="noopener" href="https://www.sparkfun.com/products/15170">SparkFun Edge Development Board - Apollo3 Blue</a> as the Development Board. You can run your demo by following the set-up of <a target="_blank" rel="noopener" href="https://codelabs.developers.google.com/codelabs/sparkfun-tensorflow#0">AI Speech Recognition with TensorFlow Lite for Microcontrollers and SparkFun Edge</a>. If you can interact with the development board by lighting colored LEDs. Then we can go to train our own models.</p>
<img style="height:300px" src="img/Embedded_AI/developing_board.png"  align=center >







<h2 id="Design-the-deep-learning-models-for-human-activities-recognition-HAR-and-make-sure-it-can-be-worked-in-the-microcontroller"><a href="#Design-the-deep-learning-models-for-human-activities-recognition-HAR-and-make-sure-it-can-be-worked-in-the-microcontroller" class="headerlink" title="Design the deep learning models for human activities recognition (HAR) and make sure it can be worked in the microcontroller "></a>Design the deep learning models for human activities recognition (HAR) and make sure it can be worked in the microcontroller <a name="b"></a></h2><p>Refering to the manual of <a target="_blank" rel="noopener" href="https://www.sparkfun.com/products/15170">SparkFun Edge Development Board - Apollo3 Blue</a>, it has ARM Cortex-M4F processor with direct memory access and 48MHz CPU clock, 96MHz with TurboSPOT™ and also gets 1MB Flash and 384KB SRAM. We should carefully construct our neural networks by limiting the memeory within 1Mb, better to be smaller than <font face="Ariel Black" size="4"> 1Mb </font>. Finally, we chose one simple CNN architecture and trained it on our human activity data that collected by an accelerometer sensor.</p>
<blockquote>
<p><font face="华文行楷" size="5"> Tips:</font> If you want to run your model faster, you can set the loss function as mean-square-error. Because cross-entropy needs more computing resource. If you want to run your model faster, you can set the loss function as mean-square-error for binary classification.</p>
</blockquote>
<table>
	<tr>
	    <td > <img style="height:250px" src="img/Embedded_AI/accuracy_embedded.bmp"  align=center >
        </td>
        <td > 
            <table border="1">
            <tr>
                <th colspan="2"><font face="Arial Black"  size="3"> Illustration of Memory and Model </font></th>
            </tr>
            <tr>
                <td rowspan="2">length of the dense layer</td>
            </tr>
            <tr>
                <td> size of bin file (kb) </td>    
            </tr>
                <tr>
                <td rowspan="2"> 15 </td>
            </tr>
            <tr>
                <td> 121 </td>    
            </tr>
                <tr>
                <td rowspan="2"> 60 </td>
            </tr>
            <tr>
                <td> 287 </td>    
            </tr>
                <tr>
                <td rowspan="2"> 97 </td>
            </tr>
            <tr>
                <td> 425 </td>    
            </tr>
                <tr>
                <td rowspan="2"> 100 </td>
            </tr>
            <tr>
                <td> 436 </td>    
            </tr>
            </table>
        </td>
	</tr>
</table>





<!-- <table border="1">
  <tr>
    <th colspan="3">物资详情说明</th>
  </tr>
  <tr>
    <td colspan="2" align="center">数量(支)</td>
    <td rowspan="2">重量(吨)</td>
  </tr>
  <tr>
    <td>实发数</td>    
    <td>实收数</td>
  </tr>
  <tr>
    <td>12</td>    
    <td>10</td>
    <td>100.00</td>
  </tr>
</table> -->


<h2 id="Using-Make-to-build-binary-file-and-deploy-it-to-the-microcontroller"><a href="#Using-Make-to-build-binary-file-and-deploy-it-to-the-microcontroller" class="headerlink" title="Using Make to build binary file and deploy it to the microcontroller "></a>Using Make to build binary file and deploy it to the microcontroller <a name="c"></a></h2><p>If you have trained your model, you should get a model file (<code>*.pb</code> or <code>*.h5</code>). But it also should be transformed to <code>*.bin</code> file. Following the manual <a target="_blank" rel="noopener" href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb">Train a Simple Audio Recognition Model</a>, we can convert the TensorFlow Model to a TensorFlow Lite Model. </p>
<blockquote>
<p><font face="华文行楷" size="5"> Tips:</font> It is better to quantize the model to a 32-bit model, you can follow the <a target="_blank" rel="noopener" href="https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb">Generate a TensorFlow Lite Model</a> to get a 32-bit TensorFlow Lite Model.</p>
</blockquote>
<!-- `code`
``Use `code` in your Markdown file.`` -->

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Install xxd <span class="keyword">if</span> it is not available</span></span><br><span class="line">!apt-get update &amp;&amp; apt-get -qq install xxd</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Convert to a C <span class="built_in">source</span> file</span></span><br><span class="line">!xxd -i &#123;MODEL_TFLITE&#125; &gt; &#123;MODEL_TFLITE_MICRO&#125;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Update variable names</span></span><br><span class="line">REPLACE_TEXT = MODEL_TFLITE.replace(&#x27;/&#x27;, &#x27;_&#x27;).replace(&#x27;.&#x27;, &#x27;_&#x27;)</span><br><span class="line">!sed -i &#x27;s/&#x27;&#123;REPLACE_TEXT&#125;&#x27;/g_model/g&#x27; &#123;MODEL_TFLITE_MICRO&#125;</span><br></pre></td></tr></table></figure>










<h2 id="Measure-model-and-microcontroller-in-terms-of-accuracy-power-consumption-and-memory-footprint"><a href="#Measure-model-and-microcontroller-in-terms-of-accuracy-power-consumption-and-memory-footprint" class="headerlink" title="Measure model and microcontroller in terms of accuracy, power consumption and memory footprint "></a>Measure model and microcontroller in terms of accuracy, power consumption and memory footprint <a name="d"></a></h2><p>Befor debugging our device, we should <font face="黑体" size="4"> (1) </font> set the port and the sampling rate, <font face="黑体" size="4"> (2) </font> initialize the inut vector and <font face="黑体" size="4"> (3) </font> choose the lose function to avoid errors. </p>
<table>
	<tr>
	    <td colspan="2"> Input <br> Vector </td>
        <td ><img style="height:250px" src="img/Embedded_AI/acc_one.bmp"  align=center ></td>
	</tr>
    <tr>
	    <td colspan="2"> Output <br> Vector </td>
        <td ><img style="height:150px" src="img/Embedded_AI/acc_two.bmp"  align=center ></td>
	</tr>
</table>


<p>When <code>constant.cc</code> is replaced with the accelerometer <code>main.cc</code> code, the function cannot be named as main, because <code>main.cc</code> file has existed which used to work with the input, model and all other things together. In order to identify the two main files, the existed main file in the beginning is called as original main. Therefore, the function name in <code>constant.cc</code> and <code>constant.h</code> both should be changed. First way is to use the ‘fun’ function to replace the ‘main’ function in the constant files. And then the original main has set a pointer 2D array to call the fun function to get the accelerometer data which shape is (64, 3). The second way is to put the codes which are in the constant files into the original main in order to get the accelerometer data as input directly. When the all recorded data are tried to put into the <code>input-&gt;data.f</code>, the error is happened in figure 34. In order to make binary file quickly, the error is put away for the moment. The input is only used the last recorded data which is changed as a 4D tensor as the trained model input. </p>
<p>In the initial example, the original output is only one value and the type is float. But the output of the designed model is a vector containing the scores for each kind of prediction,and we should figure out what the highest scoring category is. Besides, when it finds the highest score, the corresponding index would be the output of current data. The output values can only be 0, 1, 2, 3, 4 which correspond with the 5 labels–level, up, down, sedentary and sleep. </p>
<blockquote>
<p><font face="华文行楷" size="5"> Tips:</font> When you are debugging the programe, you will encounter many problems, for example, some functions in constant.cc cannot be recognized. You should added them into the makefile.inc, or add extern”c” to include the c file into the main.cc file as well as the other headers which are included in the main file.</p>
</blockquote>
<img style="height:250px" src="img/Embedded_AI/memory_layers.bmp"  align=center >

<p> Since the FLASH for this Sparkfun board is 1MB, and from the formula which shows in figure, it is easy calculated that the model can have 259 ((1024-55.026)&#x2F;3.696) dense layers including the last output layer. And the maximum parameters are about 240833 (929.9*259-10.574) on the premise that the parameters of each layer do not exceed 1000. Therefore, the maximum number of layers is totally satisfied almost all models while the units or neurons should be set carefully.</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion "></a>Conclusion <a name="e"></a></h2><p>The presented study using the microcontroller to predicts the human activity. The CNN model is firstly set according to the existing literature related to the only 3D accelerometer as the input data. Considered the limit memory footprint, the first kind of designed model has 95% accuracy. And after the quantization, it still keeps the high accuracy. However, due to the limit tensor area size and few operators in the microcontroller, the group of input data is reduced from 64 samples to the 16 samples and the model is changed again. The finally model which can be used in the microcontroller has 82% accuracy. The microcontroller is debugging success which means it is able to use its accelerometer to get the data and then analyze them to recognize the human activity by lighting the different LEDs.</p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/#About"> Profile</a></li><li class="nav_item"><a class="nav-page" href="/Publications/#index"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/Projects/#index"> Projects</a></li><li class="nav_item"><a class="nav-page" href="/Volunteer/#index"> Volunteer Experience</a></li><li class="nav_item"><a class="nav-page" href="/Blog/#index"> Blog</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2019 - 2025 by Cheng</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>